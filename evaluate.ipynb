{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import timeit\n",
    "import math\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "import re\n",
    "from lxml import etree\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import Tensor\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split, Subset\n",
    "\n",
    "from draw import show_img, show_img_grid\n",
    "from utils import postprocessing, letterbox_transforms, letterbox_label_reverse, fill_label_np_tensor, get_image_id_from_path\n",
    "from boundingbox import CoordinateType, FormatType, BoundingBoxConverter\n",
    "from transforms import IaaAugmentations, IaaLetterbox, ToTensor, Compose, \\\n",
    "                       iaa_hsv_aug, iaa_random_crop, iaa_letterbox, letterbox_reverse\n",
    "from dataset import worker_init_fn, variable_shape_collate_fn\n",
    "from darknet import YoloNet\n",
    "# from evaluate import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from contextlib import contextmanager\n",
    "from collections import OrderedDict\n",
    "import pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "def set_seed(seed):\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = './yolov3.weights'\n",
    "train_target_txt = \"./data/coco/trainvalno5k.txt\"\n",
    "valid_target_txt = \"./data/coco/5k.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco(path):\n",
    "    with open(path) as f:\n",
    "        return [line.rstrip(\"\\n\") for line in f.readlines()]\n",
    "    \n",
    "coco_path = './data/coco.names'\n",
    "classes = load_coco(coco_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations(cat_list, img_list, ann_list):\n",
    "    return OrderedDict({'categories': cat_list,\n",
    "                        'images': img_list,\n",
    "                        'annotations': ann_list})\n",
    "\n",
    "def create_images_entry(image_id, width=None, height=None):\n",
    "    if width is None or height is None:\n",
    "        return OrderedDict({'id':image_id })\n",
    "    else:\n",
    "        return OrderedDict({'id':image_id, 'width':width, 'height':height })\n",
    "\n",
    "def create_categories(class_names):\n",
    "    return [{'id':i, 'name':cls} for i, cls in enumerate(class_names)]\n",
    "\n",
    "def create_annotations_entry(image_id, bbox, category_id, ann_id, iscrowd=0, area=None, segmentation=None):\n",
    "    if area is None:\n",
    "        if segmentation is None:\n",
    "            #Calulate area with bbox\n",
    "            area = bbox[2] * bbox[3]\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    return OrderedDict({\n",
    "            \"id\": ann_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": category_id,\n",
    "            \"iscrowd\": iscrowd,\n",
    "            \"area\": area,\n",
    "            \"bbox\": bbox\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = create_images_entry(558840, 640, 427)\n",
    "img_list = [img1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = create_annotations_entry(558840, [199.84, 200.46, 77.71, 70.88], 58, 156)       \n",
    "a2 = create_annotations_entry(558840, [325.27, 104.38, 33.67, 105.99], 44, 370268)\n",
    "a3 = create_annotations_entry(558840, [1.92, 87.91, 34.95, 175.35], 47, 676791) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = create_categories(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = [a1,a2, a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_json = create_annotations(cat_list, img_list, anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"coco_annotations.json\"\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(anno_json, f, indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Results File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_entry(image_id, category_id, bbox, score):\n",
    "    return OrderedDict({\"image_id\":image_id,\n",
    "                        \"category_id\":category_id,\n",
    "                        \"bbox\":bbox,\n",
    "                        \"score\":score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = create_results_entry(558840, 58, [199.84, 200.46, 77.71, 70.88],  0.7)       \n",
    "t2 = create_results_entry(558840, 44, [10.27, 104.38, 33.67, 105.99],  0.4)  #Bad bbox\n",
    "t3 = create_results_entry(558840, 47, [1.92, 87.91, 34.95, 175.35],  0.65) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_results = [t1,t2,t3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"coco_results.json\"\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(coco_results, f, indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoGt = COCO(\"coco_annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "resFile = './coco_results.json'\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[558840]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgIds=sorted(cocoDt.getImgIds())\n",
    "imgIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.667\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "cocoEval.params.imgIds  = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Validation 5k Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Ground Truth Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_ann_list(img_path_list, label_path_list):\n",
    "    img_list, ann_list = [],[]\n",
    "    for img_path, label_path in tqdm(zip(img_path_list, label_path_list), file=sys.stdout, leave=True, total=len(img_path_list)):\n",
    "        image_id = get_image_id_from_path(img_path)\n",
    "        # Read Image\n",
    "        if osp.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "        \n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        img_list.append(create_images_entry(image_id, width, height))\n",
    "        # Read Labels\n",
    "        if osp.exists(label_path):\n",
    "            labels = np.loadtxt(label_path).reshape(-1,5)\n",
    "        labels[..., 1:5] = BoundingBoxConverter.convert(labels[..., 1:5],\n",
    "                                                     CoordinateType.Relative, FormatType.cxcywh,\n",
    "                                                     CoordinateType.Absolute, FormatType.xywh,\n",
    "                                                     img_dim=(width, height))\n",
    "\n",
    "        for label in labels:\n",
    "            category_id = int(label[0])\n",
    "            bbox = list(label[1:5])\n",
    "            ann_id = len(ann_list)\n",
    "            ann_list.append(create_annotations_entry(image_id, bbox, category_id, ann_id))\n",
    "            \n",
    "    return img_list, ann_list\n",
    "\n",
    "def create_annotations_dict(target_txt, class_names):\n",
    "    with open(target_txt, 'r') as f:\n",
    "        img_path_list = [lines.strip() for lines in f.readlines()]\n",
    "    label_path_list = [img_path.replace('jpg', 'txt').replace('images', 'labels') for img_path in img_path_list]\n",
    "    \n",
    "    img_list, ann_list = get_img_ann_list(img_path_list, label_path_list)\n",
    "    cat_list = create_categories(class_names)\n",
    "    \n",
    "    ann_dict = create_annotations(cat_list, img_list, ann_list)\n",
    "    return ann_dict\n",
    "\n",
    "def generate_annotations_file(target_txt, class_names, out):\n",
    "    ann_dict = create_annotations_dict(target_txt, class_names)\n",
    "    with open(out, 'w') as f:\n",
    "        json.dump(ann_dict, f, indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:01<00:00, 41.32it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_annotations_file(valid_target_txt, classes, 'coco_valid.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COCOEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOEvalDataset(Dataset):\n",
    "    def __init__(self, targ_txt, dim=None, transform=None):\n",
    "        with open(targ_txt, 'r') as f:\n",
    "            self.img_list = [lines.strip() for lines in f.readlines()]\n",
    "        self.label_list = [img_path.replace('jpg', 'txt').replace('images', 'labels') for img_path in self.img_list]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = None\n",
    "        img_path = self.img_list[idx]\n",
    "        if osp.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), img_path)\n",
    "        \n",
    "        label_path = self.label_list[idx]\n",
    "        if osp.exists(label_path):\n",
    "            label = np.loadtxt(label_path).reshape(-1,5)\n",
    "            \n",
    "        sample = { 'img': img, 'org_img': img.copy(), 'label': label, 'transform': None, 'img_path': img_path }\n",
    "        sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JsonPredictionWriter BatchHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def open_json_pred_writer(out_path, classes_names, is_letterbox=False):\n",
    "    pred_writer = JsonPredictionWriter(out_path, classes_names, is_letterbox)\n",
    "    try:\n",
    "        pred_writer.write_start()\n",
    "        yield pred_writer\n",
    "    finally:\n",
    "        pred_writer.write_end()\n",
    "        \n",
    "class BatchHandler:\n",
    "    def process_batch(self, sample, predictions):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class JsonPredictionWriter(BatchHandler):\n",
    "    def __init__(self, out_path, classes_names, is_letterbox=False):\n",
    "        self.out_path = out_path\n",
    "        self.file = open(out_path, 'w')\n",
    "        self.classes_names = classes_names\n",
    "        self.is_letterbox = is_letterbox\n",
    "        \n",
    "    def write_start(self):\n",
    "        self.file.write('[')\n",
    "        \n",
    "    def write_end(self):\n",
    "        self.file.seek(self.file.tell() - 1, os.SEEK_SET)\n",
    "        self.file.truncate()\n",
    "        self.file.write(']')\n",
    "        self.file.close()\n",
    "            \n",
    "    def process_batch(self, sample, predictions):\n",
    "        imgs, org_imgs, img_paths = sample['img'], sample['org_img'], sample['img_path']\n",
    "        for img, org_img, img_path, prediction in zip(imgs, org_imgs, img_paths, predictions):\n",
    "            img_w, img_h, org_w, org_h = img.shape[2], img.shape[1], org_img.shape[2], org_img.shape[1]\n",
    "            image_id = get_image_id_from_path(img_path)\n",
    "            \n",
    "            if prediction is not None and len(prediction) != 0:\n",
    "                bboxes = correct_yolo_boxes(prediction[..., 0:4], org_w, org_h, img_w, img_h, self.is_letterbox)\n",
    "                category_ids = prediction[..., 6]\n",
    "                scores = prediction[..., 5]\n",
    "                               \n",
    "                for category_id, bbox, score in zip(category_ids, bboxes, scores):\n",
    "                    category_id, bbox, score = int(category_id.item()), bbox.tolist(), score.item()\n",
    "                    res = create_results_entry(image_id, category_id, bbox, score)\n",
    "                    json.dump(res, self.file, indent=4, separators=(',', ':'))\n",
    "                    self.file.write(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct Yolo Boxes (Reverse letterbox or rescale from network image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_bbox(labels, org_w, org_h, new_w, new_h):\n",
    "    if len(labels) == 0:\n",
    "        return labels\n",
    "\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.clone()\n",
    "    elif isinstance(labels, np.ndarray):\n",
    "        labels = labels.copy()\n",
    "    else:\n",
    "        raise TypeError(\"Labels must be a numpy array or pytorch tensor\")\n",
    "\n",
    "    ratio_x, ratio_y = new_w / org_w, new_h / org_h\n",
    "    mask = labels.sum(-1) != 0\n",
    "    labels[mask, 0] = np.clip((labels[mask, 0]) / ratio_x, 0, org_w)\n",
    "    labels[mask, 2] = np.clip((labels[mask, 2]) / ratio_x, 0, org_w)\n",
    "    labels[mask, 1] = np.clip((labels[mask, 1]) / ratio_y, 0, org_h)\n",
    "    labels[mask, 3] = np.clip((labels[mask, 3]) / ratio_y, 0, org_h)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def correct_yolo_boxes(bboxes, org_w, org_h, img_w, img_h, is_letterbox=False):\n",
    "    if is_letterbox:\n",
    "        bboxes = letterbox_reverse(bboxes, org_w, org_h, img_w, img_h)\n",
    "    else:\n",
    "        bboxes = rescale_bbox(bboxes, org_w, org_h, img_w, img_h)\n",
    "\n",
    "    bboxes = BoundingBoxConverter.convert(bboxes, \n",
    "                                          CoordinateType.Absolute, FormatType.x1y1x2y2,\n",
    "                                          CoordinateType.Absolute, FormatType.xywh,\n",
    "                                          img_dim=(img_w, img_h))\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_process(data, net, num_classes, batch_handler=None):\n",
    "    with torch.no_grad(): \n",
    "        for sample in tqdm(data, file=sys.stdout, leave=True):           \n",
    "            # Pass images to the network\n",
    "            det1, det2, det3 = net(sample['img'].cuda(), None)\n",
    "            predictions = postprocessing(torch.cat((det1,det2,det3), 1),\n",
    "                                         num_classes, obj_conf_thr=0.005, nms_thr=0.45,\n",
    "                                         is_eval=True, use_nms=True)\n",
    "            # Batch Handler - write file\n",
    "            batch_handler.process_batch(sample, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results_file(net, target_txt, classes_names, out, bs, dim, is_letterbox=False):\n",
    "    numclass = len(classes_names)\n",
    "    if is_letterbox:\n",
    "        transform = Compose([IaaAugmentations([IaaLetterbox(dim)]), ToTensor()])\n",
    "    else:\n",
    "        transform = Compose([IaaAugmentations([iaa.Scale(dim)]), ToTensor()])\n",
    "\n",
    "    ds = COCOEvalDataset(target_txt, dim, transform)\n",
    "    dl = DataLoader(ds, batch_size=bs, num_workers=4, collate_fn=variable_shape_collate_fn)\n",
    "\n",
    "    with open_json_pred_writer(out, classes_names, is_letterbox) as pred_writer:\n",
    "        predict_and_process(dl, net, num_classes=numclass, batch_handler=pred_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Results File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "sz = 416\n",
    "dim = (sz, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [02:30<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "net = YoloNet(dim, numClass=80).cuda().eval()\n",
    "net.loadWeight(weight_path, 'darknet')\n",
    "\n",
    "generate_results_file(net, valid_target_txt, classes, 'coco_valid_result.json', bs, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoGt = COCO(\"coco_valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=1.81s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "resFile = './coco_valid_result.json'\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgIds=sorted(cocoDt.getImgIds())\n",
    "len(imgIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=50.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.86s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n"
     ]
    }
   ],
   "source": [
    "cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "cocoEval.params.imgIds  = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVATDataset (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text File Output (TODO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
